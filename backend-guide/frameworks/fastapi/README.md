# FastAPI Backend for SmartHealthQuote

This guide helps you build a FastAPI backend with LLM integration and RAG pipeline for the health insurance quote system.

## ğŸš€ Quick Start

1. **Setup Project**:
   ```bash
   mkdir smarthealth-backend && cd smarthealth-backend
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Run Development Server**:
   ```bash
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

3. **API Documentation**: Visit `http://localhost:8000/docs`

## ğŸ“ Project Structure

```
smarthealth-backend/
â”œâ”€â”€ main.py                 # FastAPI app entry point
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py      # Main API endpoints
â”‚   â”‚   â””â”€â”€ models.py      # Pydantic models
â”‚   â”œâ”€â”€ core/              # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py      # Configuration
â”‚   â”‚   â”œâ”€â”€ security.py    # Authentication
â”‚   â”‚   â””â”€â”€ database.py    # Database connection
â”‚   â”œâ”€â”€ services/          # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py # LLM integration
â”‚   â”‚   â”œâ”€â”€ rag_service.py # RAG pipeline
â”‚   â”‚   â””â”€â”€ quote_service.py # Quote generation
â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ insurance.py   # Insurance data models
â”‚   â””â”€â”€ data/              # Sample data
â”‚       â”œâ”€â”€ policies.json
â”‚       â””â”€â”€ providers.json
â”œâ”€â”€ tests/                 # Test files
â”œâ”€â”€ docker-compose.yml     # Local development
â””â”€â”€ Dockerfile            # Container definition
```

## âš¡ Key Features

- **ğŸš€ High Performance**: Async/await for concurrent requests
- **ğŸ“š Auto Documentation**: Interactive API docs with Swagger UI
- **ğŸ”’ Type Safety**: Pydantic models for request/response validation
- **ğŸ¤– LLM Integration**: Support for multiple LLM providers
- **ğŸ” Vector Search**: FAISS/Pinecone integration for RAG
- **ğŸ›¡ï¸ Security**: JWT authentication, CORS, rate limiting
- **ğŸ“Š Monitoring**: Request logging and health checks

## ğŸ”§ Configuration

FastAPI offers excellent flexibility for different deployment scenarios:

### Development
- SQLite database
- Local FAISS vector store  
- Debug logging
- Hot reload

### Production
- PostgreSQL database
- Managed vector DB (Pinecone)
- Structured logging
- Performance monitoring

## ğŸ“– Implementation Guide

1. [Setup & Installation](setup.md)
2. [API Design](api-design.md) 
3. [LLM Integration](llm-integration.md)
4. [RAG Pipeline](rag-pipeline.md)
5. [Database Setup](database.md)
6. [Authentication](authentication.md)
7. [Testing](testing.md)
8. [Deployment](deployment.md)

## ğŸŒŸ Why FastAPI?

- **Perfect for ML/AI**: Excellent support for data science libraries
- **Production Ready**: Used by companies like Uber, Netflix
- **Great Documentation**: Automatic OpenAPI schema generation
- **Modern Python**: Built on Python 3.6+ with type hints
- **High Performance**: Comparable to Node.js and Go

## ğŸ¤ Integration with React Frontend

Your React app will connect to these endpoints:

```javascript
// In your React app (src/pages/chat.jsx)
const getQuotation = async () => {
  const response = await fetch('http://localhost:8000/api/quote', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(formData)
  });
  return response.json();
};
```

## ğŸƒâ€â™‚ï¸ Next Steps

1. **Follow the setup guide**: [setup.md](setup.md)
2. **Run the demo**: See working examples in action
3. **Customize**: Adapt the code to your specific needs
4. **Deploy**: Use the deployment guide for production

Ready to build? Start with the [setup guide](setup.md)!